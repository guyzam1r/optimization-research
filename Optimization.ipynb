{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c85ed7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46639f95",
   "metadata": {},
   "source": [
    "## Objective Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d239de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere(x):\n",
    "    return torch.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a03631c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipsoid(x):\n",
    "    n = x.size(0)\n",
    "    out = 0\n",
    "    for i in range(n):\n",
    "        out += x[i]**2 * 10**(6 * i / (n-1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f61925b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cigar(x):\n",
    "    return x[0]**2 + 10**6 * torch.sum(x[1:]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b107490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tablet(x):\n",
    "    return 10**6 * x[0]**2 + torch.sum(x[1:]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5a166d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabolic_ridge(x):\n",
    "    return -x[0] + 100*torch.sum(x[1:]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0bf66235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharp_ridge(x):\n",
    "    return -x[0] + 100*torch.norm(x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7b5d2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffpow(x):\n",
    "    n = x.size(0)\n",
    "    out = 0\n",
    "    for i in range(n):\n",
    "        out += torch.abs(x[i])**(2 + 10*i/(n-1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7545738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    n = x.size(0)\n",
    "    out = 0\n",
    "    for i in range(n-1):\n",
    "        out += 100*(x[i+1] - x[i]**2)**2 + (x[i] - 1)**2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d998a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Only takes x in R^2\n",
    "def booth(x):\n",
    "    return (x[0] + 2*x[1] - 7)**2 + (2*x[0] + x[1] - 5)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3825a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2ecf4",
   "metadata": {},
   "source": [
    "# Gradient-Based Optimization Methods\n",
    "\n",
    "Source: https://algorithmsbook.com/optimization/files/optimization.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c10a903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent\n",
    "def gd_step(x, obj, params):\n",
    "    lr = params[\"lr\"]\n",
    "    \n",
    "    loss = obj(x)\n",
    "    grad, = torch.autograd.grad(loss, inputs=x)\n",
    "    x_new = x - lr*grad\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0fef7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Momentum\n",
    "def momentum_step(x, obj, params):\n",
    "    lr = params[\"lr\"]\n",
    "    v = params[\"v\"]\n",
    "    decay = params[\"decay\"]\n",
    "    \n",
    "    loss = obj(x)\n",
    "    grad, = torch.autograd.grad(loss, inputs=x)\n",
    "    v_new = decay*v - lr*grad\n",
    "    x_new = x + v_new\n",
    "    return x_new, v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d687fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaGrad\n",
    "def adagrad_step(x, obj, params):\n",
    "    lr = params[\"lr\"]\n",
    "    s = params[\"s\"]\n",
    "    \n",
    "    loss = obj(x)\n",
    "    grad, = torch.autograd.grad(loss, inputs=x)\n",
    "    s_new = s + grad**2\n",
    "    x_new = x - (lr / (10e-8 + torch.sqrt(s_new)))*grad\n",
    "    return x_new, s_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5be8a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "cf42da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam\n",
    "def adam_step(x, obj, params):\n",
    "    v = params[\"v\"]\n",
    "    v_decay = params[\"v_decay\"]\n",
    "    s = params[\"s\"]\n",
    "    s_decay = params[\"s_decay\"]\n",
    "    lr = params[\"lr\"]\n",
    "    k = params[\"k\"] #stores number of iterations\n",
    "    \n",
    "    k += 1\n",
    "    \n",
    "    loss = obj(x)\n",
    "    grad, = torch.autograd.grad(loss, inputs=x)\n",
    "    \n",
    "    v_new = v_decay*v + (1-v_decay)*grad\n",
    "    s_new = s_decay*s + (1-s_decay)*(grad**2)\n",
    "    \n",
    "    v_hat = v_new / (1 - v_decay**k)\n",
    "    s_hat = s_new / (1 - s_decay**k)\n",
    "    \n",
    "    x_new = x - lr * v_hat / (1e-8 + torch.sqrt(s_hat))\n",
    "    return x_new, v_new, s_new, k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e91b44",
   "metadata": {},
   "source": [
    "## CMA-ES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b93b3e",
   "metadata": {},
   "source": [
    "Source: http://www.cmap.polytechnique.fr/~nikolaus.hansen/evco_11_1_1_0.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4eecfa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oldcmaes_step(x, obj, params):\n",
    "    l = params[\"l\"]\n",
    "    mu = params[\"mu\"]\n",
    "    C = params[\"C\"]\n",
    "    pc = params[\"pc\"]\n",
    "    cc = params[\"cc\"]\n",
    "    ccov = params[\"ccov\"]\n",
    "    s = params[\"s\"]\n",
    "    ps = params[\"ps\"]\n",
    "    cs = params[\"cs\"]\n",
    "    ds = params[\"ds\"]\n",
    "    chi = params[\"chi\"]\n",
    "    n = x.size(0)\n",
    "    \n",
    "    #compute B and D\n",
    "    B, D_squared, B_transpose = torch.linalg.svd(C)\n",
    "    D = torch.diag(torch.sqrt(D_squared))\n",
    "    BD = torch.matmul(B,D)\n",
    "    \n",
    "    #Sample offspring\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(n), torch.eye(n))\n",
    "    z = m.sample((l,))\n",
    "    offspring = x + s * torch.t(torch.matmul(BD, torch.t(z)))\n",
    "        \n",
    "    #Compute objective on each offspring\n",
    "    evals = torch.zeros(l)\n",
    "    for i in range(l):\n",
    "        evals[i] = obj(offspring[i])\n",
    "        \n",
    "    #Get indices of top mu offspring\n",
    "    top_evals, top_inds = torch.topk(evals, mu, largest=False)\n",
    "    \n",
    "    #Updates\n",
    "    x_new = (1/mu) * torch.sum(offspring[top_inds], dim=0)\n",
    "    z_avg = (1/mu) * torch.sum(z[top_inds], dim=0)\n",
    "    \n",
    "    #Covariance update\n",
    "    pc_new = (1-cc)*pc + np.sqrt(cc*(2-cc)*mu) * torch.matmul(BD, z_avg)\n",
    "    C_new = (1-ccov)*C + ccov*torch.outer(pc_new, pc_new)\n",
    "    \n",
    "    #Step size update\n",
    "    ps_new = (1-cs)*ps + np.sqrt(cs*(2-cs)*mu) * torch.matmul(B, z_avg)\n",
    "    s_new = s * torch.exp((1/ds) * (torch.norm(ps_new)-chi) / chi)\n",
    "    \n",
    "    return x_new, C_new, pc_new, s_new, ps_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e367a467",
   "metadata": {},
   "source": [
    "Source: http://www.cmap.polytechnique.fr/~nikolaus.hansen/evco_11_1_1_0.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "23a6be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newcmaes_step(x, obj, params):\n",
    "    l = params[\"l\"]\n",
    "    mu = params[\"mu\"]\n",
    "    C = params[\"C\"]\n",
    "    pc = params[\"pc\"]\n",
    "    cc = params[\"cc\"]\n",
    "    ccov = params[\"ccov\"]\n",
    "    acov = params[\"acov\"]\n",
    "    s = params[\"s\"]\n",
    "    ps = params[\"ps\"]\n",
    "    cs = params[\"cs\"]\n",
    "    ds = params[\"ds\"]\n",
    "    chi = params[\"chi\"]\n",
    "    n = x.size(0)\n",
    "    \n",
    "    #compute B and D\n",
    "    B, D_squared, B_transpose = torch.linalg.svd(C)\n",
    "    D = torch.diag(torch.sqrt(D_squared))\n",
    "    BD = torch.matmul(B,D)\n",
    "    \n",
    "    #Sample offspring\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(n), torch.eye(n))\n",
    "    z = m.sample((l,))\n",
    "    offspring = x + s * torch.t(torch.matmul(BD, torch.t(z)))\n",
    "        \n",
    "    #Compute objective on each offspring\n",
    "    evals = torch.zeros(l)\n",
    "    for i in range(l):\n",
    "        evals[i] = obj(offspring[i])\n",
    "        \n",
    "    #Get indices of top mu offspring\n",
    "    top_evals, top_inds = torch.topk(evals, mu, largest=False)\n",
    "    \n",
    "    #Updates\n",
    "    x_new = (1/mu) * torch.sum(offspring[top_inds], dim=0)\n",
    "    z_avg = (1/mu) * torch.sum(z[top_inds], dim=0)\n",
    "    \n",
    "    #Covariance update\n",
    "    pc_new = (1-cc)*pc + np.sqrt(cc*(2-cc)*mu) * torch.matmul(BD, z_avg)\n",
    "    \n",
    "    outer_prod_sum = torch.zeros(n,n)\n",
    "    for i in range(mu):\n",
    "        outer_prod_sum += (1/mu) * torch.outer(z[top_inds[i]], z[top_inds[i]])\n",
    "    bigZ = torch.matmul(BD, torch.matmul(outer_prod_sum, torch.t(BD)))\n",
    "    \n",
    "    C_new = ((1-ccov)*C + \n",
    "             ccov * (acov*torch.matmul(pc_new, torch.t(pc_new)) +\n",
    "                     (1-acov)*bigZ))\n",
    "    \n",
    "    #Step size update\n",
    "    ps_new = (1-cs)*ps + np.sqrt(cs*(2-cs)*mu) * torch.matmul(B, z_avg)\n",
    "    s_new = s * torch.exp((1/ds) * (torch.norm(ps_new)-chi) / chi)\n",
    "    \n",
    "    return x_new, C_new, pc_new, s_new, ps_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a701a88",
   "metadata": {},
   "source": [
    "Source: https://arxiv.org/pdf/1604.00772.pdf (see pg. 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "0b953744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - finish hs\n",
    "def cmaes_step(x, obj, params):\n",
    "    #Set parameters\n",
    "    l = params[\"l\"]\n",
    "    mu = params[\"mu\"]\n",
    "    mu_eff = params[\"mu_eff\"]\n",
    "    C = params[\"C\"]\n",
    "    pc = params[\"pc\"]\n",
    "    cc = params[\"cc\"]\n",
    "    cm = params[\"cm\"]\n",
    "    c1 = params[\"c1\"]\n",
    "    cmu = params[\"cmu\"]\n",
    "    s = params[\"s\"]\n",
    "    ps = params[\"ps\"]\n",
    "    cs = params[\"cs\"]\n",
    "    ds = params[\"ds\"]\n",
    "    chi = params[\"chi\"]\n",
    "    w = params[\"w\"]\n",
    "    sumw = params[\"sumw\"]\n",
    "    n = x.size(0)\n",
    "    \n",
    "    #Calculate B,D\n",
    "    B, D_squared_diag, B_transpose = torch.linalg.svd(C)\n",
    "    D_diag = torch.sqrt(D_squared_diag)\n",
    "    D = torch.diag(D_diag)\n",
    "    Dinv = torch.diag(1/D_diag)\n",
    "    BD = torch.matmul(B,D)\n",
    "    sqrtCinv = torch.matmul(B, torch.matmul(Dinv, B_transpose))\n",
    "    \n",
    "    #Sample offspring\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(n), torch.eye(n))\n",
    "    z = m.sample((l,))\n",
    "    y = torch.matmul(BD, z)\n",
    "    offspring = x + s*y\n",
    "    \n",
    "    #Compute objective on each offspring\n",
    "    evals = torch.zeros(l)\n",
    "    for i in range(l):\n",
    "        evals[i] = obj(offspring[i])\n",
    "    \n",
    "    #Get indices of top mu offspring\n",
    "    top_evals, top_inds = torch.topk(evals, l, largest=False)\n",
    "    \n",
    "    #Selection and recombination\n",
    "    y_avg = torch.zeros(n)\n",
    "    for i in range(mu):\n",
    "        y_avg += w[i] * y[top_inds[i]]\n",
    "    x_new = x + cm*s*y_avg\n",
    "\n",
    "    #Covariance update    \n",
    "    hs = 0 #Annoying\n",
    "    dhs = (1-hs) * cc * (2-cc)\n",
    "    \n",
    "    w_circle = torch.zeros(l)\n",
    "    w_circle[:mu] = w[:mu]\n",
    "    for i in range(mu, l):\n",
    "        w_circle[i] = w[i] * n / torch.norm(torch.matmul(sqrtCinv, y[top_inds[i]]))**2\n",
    "    \n",
    "    pc_new = (1-cc)*pc + hs*np.sqrt(cc*(2-cc)*mu_eff)*y_avg\n",
    "\n",
    "    outer_prod_sum = torch.zeros(n,n)\n",
    "    for i in range(l):\n",
    "        outer_prod_sum += w_circle[i] * torch.outer(y[top_inds[i]], y[top_inds[i]])\n",
    "    \n",
    "    C_new = ((1 + c1*dhs - c1 - cmu*sumw)*C +\n",
    "         c1*torch.outer(pc, pc) +\n",
    "         cmu*outer_prod_sum)\n",
    "    \n",
    "    #Step size update\n",
    "    ps_new = (1-cs)*ps + np.sqrt(cs*(2-cs)*mu_eff) * torch.matmul(sqrtCinv, y_avg)\n",
    "    s_new = s * torch.exp((cs/ds) * (torch.norm(ps)/chi - 1))\n",
    "    \n",
    "    return x_new, C_new, pc_new, s_new, ps_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f77ce",
   "metadata": {},
   "source": [
    "## Optimizer Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "6f16f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(optimizer, x, obj):\n",
    "    if optimizer == \"gd\":\n",
    "        x_new = gd_step(x, obj, parameters[\"gd\"])\n",
    "        \n",
    "    elif optimizer == \"momentum\":\n",
    "        x_new, v_new = momentum_step(x, obj, parameters[\"momentum\"])\n",
    "        parameters[\"momentum\"][\"v\"] = v_new\n",
    "        \n",
    "    elif optimizer == \"adagrad\":\n",
    "        x_new, s_new = adagrad_step(x, obj, parameters[\"adagrad\"])\n",
    "        parameters[\"adagrad\"][\"s\"] = s_new\n",
    "        \n",
    "    elif optimizer == \"rmsprop\":\n",
    "        pass\n",
    "    \n",
    "    elif optimizer == \"adam\":\n",
    "        x_new, v_new, s_new, k = adam_step(x, obj, parameters[\"adam\"])\n",
    "        parameters[\"adam\"][\"v\"] = v_new\n",
    "        parameters[\"adam\"][\"s\"] = s_new\n",
    "        parameters[\"adam\"][\"k\"] = k\n",
    "    \n",
    "    elif optimizer == \"oldcmaes\":\n",
    "        x_new, C_new, pc_new, s_new, ps_new = oldcmaes_step(x, obj, parameters[\"oldcmaes\"])\n",
    "        parameters[\"oldcmaes\"][\"C\"] = C_new\n",
    "        parameters[\"oldcmaes\"][\"pc\"] = pc_new\n",
    "        parameters[\"oldcmaes\"][\"s\"] = s_new\n",
    "        parameters[\"oldcmaes\"][\"ps\"] = ps_new\n",
    "        \n",
    "    elif optimizer == \"newcmaes\":\n",
    "        x_new, C_new, pc_new, s_new, ps_new = newcmaes_step(x, obj, parameters[\"newcmaes\"])\n",
    "        parameters[\"newcmaes\"][\"C\"] = C_new\n",
    "        parameters[\"newcmaes\"][\"pc\"] = pc_new\n",
    "        parameters[\"newcmaes\"][\"s\"] = s_new\n",
    "        parameters[\"newcmaes\"][\"ps\"] = ps_new\n",
    "        \n",
    "    elif optimizer == \"cmaes\":\n",
    "        x_new, C_new, pc_new, s_new, ps_new = cmaes_step(x, obj, parameters[\"cmaes\"])\n",
    "        parameters[\"cmaes\"][\"C\"] = C_new\n",
    "        parameters[\"cmaes\"][\"pc\"] = pc_new\n",
    "        parameters[\"cmaes\"][\"s\"] = s_new\n",
    "        parameters[\"cmaes\"][\"ps\"] = ps_new\n",
    "    \n",
    "    else:\n",
    "        print(\"Optimizer\", optimizer, \"not found.\")\n",
    "        \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac4464",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "d305ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_params(n):\n",
    "    gd_params = {\n",
    "        \"lr\": 0.0001\n",
    "    }\n",
    "\n",
    "    momentum_params = {\n",
    "        \"lr\": 0.001,\n",
    "        \"v\": 0,\n",
    "        \"decay\": 0.5\n",
    "    }\n",
    "\n",
    "    adagrad_params = {\n",
    "        \"lr\": 1,\n",
    "        \"s\": 0\n",
    "    }\n",
    "\n",
    "    rmsprop_params = {}\n",
    "\n",
    "    adam_params = {\n",
    "        \"lr\": 0.3,\n",
    "        \"v\": 0,\n",
    "        \"s\": 0,\n",
    "        \"v_decay\": 0.9,\n",
    "        \"s_decay\": 0.999,\n",
    "        \"k\": 0\n",
    "    }\n",
    "    \n",
    "    #OLD/NEW CMAES PARAMETERS\n",
    "    l = int(4 + np.floor(3*np.log(n)))\n",
    "    mu = int(np.floor(l/4))\n",
    "    chi = np.sqrt(n) * (1 - 1/(4*n) + 1/(21*n**2))\n",
    "    acov = 1/mu\n",
    "    \n",
    "    oldcmaes_params = {\n",
    "        \"l\": l,\n",
    "        \"mu\": mu,\n",
    "        \"C\": torch.eye(n),\n",
    "        \"pc\": torch.zeros(n),\n",
    "        \"cc\": 4 / (n+4),\n",
    "        \"ccov\": 2 / (n + np.sqrt(2))**2,\n",
    "        \"s\": 1,\n",
    "        \"ps\": torch.zeros(n),\n",
    "        \"cs\": 4/(n+4),\n",
    "        \"ds\": 1 + (n+4)/4,\n",
    "        \"chi\": chi\n",
    "    }\n",
    "    \n",
    "    newcmaes_params = {\n",
    "        \"l\": l,\n",
    "        \"mu\": mu,\n",
    "        \"C\": torch.eye(n),\n",
    "        \"pc\": torch.zeros(n),\n",
    "        \"cc\": 4 / (n+4),\n",
    "        \"ccov\": acov*2/(n+np.sqrt(2))**2 + (1-acov)*min(1, (2*mu-1)/((n+2)**2 + mu)),\n",
    "        \"acov\": acov,\n",
    "        \"s\": 1,\n",
    "        \"ps\": torch.zeros(n),\n",
    "        \"cs\": 4/(n+4),\n",
    "        \"ds\": 1 + (n+4)/4,\n",
    "        \"chi\": chi\n",
    "    }\n",
    "    \n",
    "    #CMAES PARAMETERS\n",
    "    l = int(4 + np.floor(3 * np.log(n)))\n",
    "    mu = int(np.floor(l/2))\n",
    "    \n",
    "    w_prime = np.log((l+1)/2) - torch.log(torch.arange(1,l+1))\n",
    "        \n",
    "    mu_eff = (torch.sum(w_prime[:mu])**2) / torch.sum(w_prime[:mu]**2)\n",
    "    mu_eff_neg = (torch.sum(w_prime[mu:])**2) / torch.sum(w_prime[mu:]**2)\n",
    "    \n",
    "    cm = 1\n",
    "    \n",
    "    cs = (mu_eff + 2) / (n + mu_eff + 5)\n",
    "    ds = 1 + 2 * max(0, np.sqrt((mu_eff-1)/(n+1))-1) + cs\n",
    "    \n",
    "    cc = (4 + mu_eff/n) / (n + 4 + 2*mu_eff/n)\n",
    "    c1 = 2 / ((n+1.3)**2 + mu_eff)\n",
    "    cmu = min(1-c1, 2*(1/4 + mu_eff + 1/mu_eff - 2)/((n+2)**2 + mu_eff))\n",
    "    \n",
    "    amu = 1 + c1/cmu\n",
    "    amu_eff = 1 + (2*mu_eff_neg) / (mu_eff + 2)\n",
    "    a_pd = (1 - c1 - cmu) / (n*cmu)\n",
    "    \n",
    "    sum_w_prime_pos = torch.sum(w_prime[:mu])\n",
    "    sum_w_prime_neg = -torch.sum(w_prime[mu:])\n",
    "    \n",
    "    w = torch.zeros(l)\n",
    "    w[:mu] = w_prime[:mu] / sum_w_prime_pos\n",
    "    w[mu:] = min(amu, amu_eff, a_pd) * w_prime[mu:] / sum_w_prime_neg\n",
    "    sumw = torch.sum(w)\n",
    "    \n",
    "    chi = np.sqrt(1 - 1/(4*n) + 1/(21*n**2))\n",
    "    \n",
    "    cmaes_params = {\n",
    "        \"l\": l,\n",
    "        \"mu\": mu,\n",
    "        \"mu_eff\": mu_eff,\n",
    "        \"C\": torch.eye(n),\n",
    "        \"pc\": torch.zeros(n),\n",
    "        \"cc\": cc,\n",
    "        \"cm\": cm,\n",
    "        \"c1\": c1,\n",
    "        \"cmu\": cmu,\n",
    "        \"s\": 0.1,\n",
    "        \"ps\": torch.zeros(n),\n",
    "        \"cs\": cs,\n",
    "        \"ds\": ds,\n",
    "        \"chi\": chi,\n",
    "        \"w\": w,\n",
    "        \"sumw\": sumw\n",
    "    }\n",
    "\n",
    "    parameters = {\n",
    "        \"gd\": gd_params,\n",
    "        \"momentum\": momentum_params,\n",
    "        \"adagrad\": adagrad_params,\n",
    "        \"rmsprop\": rmsprop_params,\n",
    "        \"adam\": adam_params,\n",
    "        \"oldcmaes\": oldcmaes_params,\n",
    "        \"newcmaes\": newcmaes_params,\n",
    "        \"cmaes\": cmaes_params\n",
    "    }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a820b",
   "metadata": {},
   "source": [
    "## Training/Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "55f0eaf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial x: tensor([1., 2., 3., 4., 5.], requires_grad=True)\n",
      "epoch 0 | 14814.0\n",
      "epoch 500 | 1.5921648740768433\n",
      "epoch 1000 | 1.253328561782837\n",
      "epoch 1500 | 0.8334202766418457\n",
      "epoch 2000 | 0.4226188659667969\n",
      "epoch 2500 | 0.13334880769252777\n",
      "epoch 3000 | 0.019047601148486137\n",
      "epoch 3500 | 0.5619878768920898\n",
      "epoch 4000 | 2.4986173229990527e-05\n",
      "epoch 4500 | 5.5500800954177976e-05\n",
      "epoch 5000 | 9.697453788248822e-05\n",
      "Final x: tensor([0.9989, 0.9979, 0.9958, 0.9915, 0.9831], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 5001\n",
    "optimizer = \"adam\"\n",
    "obj = rosenbrock\n",
    "x = torch.arange(start=1,end=6, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "print(\"Initial x:\", x)\n",
    "\n",
    "parameters = set_params(x.size(0))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % 500 == 0:\n",
    "        print(\"epoch\", epoch, \"|\",obj(x).item())\n",
    "        #print(x)\n",
    "    x = step(optimizer, x, obj)\n",
    "\n",
    "print(\"Final x:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ea8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
