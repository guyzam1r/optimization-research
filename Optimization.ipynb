{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c85ed7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46639f95",
   "metadata": {},
   "source": [
    "## Objective Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d239de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere(x):\n",
    "    return torch.sum(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a7402d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipsoid(x):\n",
    "    n = x.size(0)\n",
    "    out = 0\n",
    "    for i in range(n):\n",
    "        out += x[i]**2 * 10**(6 * i / (n-1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1b2c996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cigar(x):\n",
    "    return x[0]**2 + 10**6 * torch.sum(x[1:]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b7d9cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tablet(x):\n",
    "    return 10**6 * x[0]**2 + torch.sum(x[1:]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ab56d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabolic_ridge(x):\n",
    "    return -x[0] + 100*torch.sum(x[1:]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bbaf106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharp_ridge(x):\n",
    "    return -x[0] + 100*torch.norm(x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8c815a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffpow(x):\n",
    "    n = x.size(0)\n",
    "    out = 0\n",
    "    for i in range(n):\n",
    "        out += torch.abs(x[i])**(2 + 10*i/(n-1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7545738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    n = x.size(0)\n",
    "    out = 0\n",
    "    for i in range(n-1):\n",
    "        out += 100*(x[i+1] - x[i]**2)**2 + (x[i] - 1)**2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d998a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Only takes x in R^2\n",
    "def booth(x):\n",
    "    return (x[0] + 2*x[1] - 7)**2 + (2*x[0] + x[1] - 5)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3825a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2ecf4",
   "metadata": {},
   "source": [
    "# Gradient-Based Optimization Methods\n",
    "\n",
    "Source: https://algorithmsbook.com/optimization/files/optimization.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c10a903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent\n",
    "def gd_step(x, obj, params):\n",
    "    lr = params[\"lr\"]\n",
    "    \n",
    "    loss = obj(x)\n",
    "    grad, = torch.autograd.grad(loss, inputs=x)\n",
    "    x_new = x - lr*grad\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0fef7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Momentum\n",
    "def momentum_step(x, obj, params):\n",
    "    lr = params[\"lr\"]\n",
    "    v = params[\"v\"]\n",
    "    decay = params[\"decay\"]\n",
    "    \n",
    "    loss = obj(x)\n",
    "    grad, = torch.autograd.grad(loss, inputs=x)\n",
    "    v_new = decay*v - lr*grad\n",
    "    x_new = x + v_new\n",
    "    return x_new, v_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d687fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaGrad\n",
    "def adagrad_step(x, obj, params):\n",
    "    lr = params[\"lr\"]\n",
    "    s = params[\"s\"]\n",
    "    \n",
    "    loss = obj(x)\n",
    "    grad, = torch.autograd.grad(loss, inputs=x)\n",
    "    s_new = s + grad**2\n",
    "    x_new = x - (lr / (10e-8 + torch.sqrt(s_new)))*grad\n",
    "    return x_new, s_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5be8a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "cf42da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam\n",
    "def adam_step(x, obj, params):\n",
    "    v = params[\"v\"]\n",
    "    v_decay = params[\"v_decay\"]\n",
    "    s = params[\"s\"]\n",
    "    s_decay = params[\"s_decay\"]\n",
    "    lr = params[\"lr\"]\n",
    "    k = params[\"k\"] #stores number of iterations\n",
    "    \n",
    "    k += 1\n",
    "    \n",
    "    loss = obj(x)\n",
    "    grad, = torch.autograd.grad(loss, inputs=x)\n",
    "    \n",
    "    v_new = v_decay*v + (1-v_decay)*grad\n",
    "    s_new = s_decay*s + (1-s_decay)*(grad**2)\n",
    "    \n",
    "    v_hat = v_new / (1 - v_decay**k)\n",
    "    s_hat = s_new / (1 - s_decay**k)\n",
    "    \n",
    "    x_new = x - lr * v_hat / (1e-8 + torch.sqrt(s_hat))\n",
    "    return x_new, v_new, s_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e91b44",
   "metadata": {},
   "source": [
    "## CMA-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de596730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: \n",
    "#fix transposes\n",
    "#make sure all matrix multiplications have correct dims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538d023a",
   "metadata": {},
   "source": [
    "Source: http://www.cmap.polytechnique.fr/~nikolaus.hansen/evco_11_1_1_0.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4eecfa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oldcmaes_step(x, obj, params):\n",
    "    l = params[\"l\"]\n",
    "    mu = params[\"mu\"]\n",
    "    C = params[\"C\"]\n",
    "    pc = params[\"pc\"]\n",
    "    cc = params[\"cc\"]\n",
    "    ccov = params[\"ccov\"]\n",
    "    s = params[\"s\"]\n",
    "    ps = params[\"ps\"]\n",
    "    cs = params[\"cs\"]\n",
    "    ds = params[\"ds\"]\n",
    "    chi = params[\"chi\"]\n",
    "    n = x.size(0)\n",
    "    \n",
    "    #compute B and D\n",
    "    B, D_squared, B_transpose = torch.linalg.svd(C)\n",
    "    D = torch.diag(torch.sqrt(D_squared))\n",
    "    BD = torch.matmul(B,D)\n",
    "    \n",
    "    #Sample offspring\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(n), torch.eye(n))\n",
    "    z = m.sample((l,))\n",
    "    offspring = x + s * torch.t(torch.matmul(BD, torch.t(z)))\n",
    "        \n",
    "    #Compute objective on each offspring\n",
    "    evals = torch.zeros(l)\n",
    "    for i in range(l):\n",
    "        evals[i] = obj(offspring[i])\n",
    "        \n",
    "    #Get indices of top mu offspring\n",
    "    top_evals, top_inds = torch.topk(evals, mu, largest=False)\n",
    "    \n",
    "    #Updates\n",
    "    x_new = (1/mu) * torch.sum(offspring[top_inds], dim=0)\n",
    "    z_avg = (1/mu) * torch.sum(z[top_inds], dim=0)\n",
    "    \n",
    "    #Covariance update\n",
    "    pc_new = (1-cc)*pc + np.sqrt(cc*(2-cc)*mu) * torch.matmul(BD, z_avg)\n",
    "    C_new = (1-ccov)*C + ccov*torch.outer(pc_new, pc_new)\n",
    "    \n",
    "    #Step size update\n",
    "    ps_new = (1-cs)*ps + np.sqrt(cs*(2-cs)*mu) * torch.matmul(B, z_avg)\n",
    "    s_new = s * torch.exp((1/ds) * (torch.norm(ps_new)-chi) / chi)\n",
    "    \n",
    "    return x_new, C_new, pc_new, s_new, ps_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "9fd3f7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 2, 4, 6],\n",
       "        [0, 3, 6, 9]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.outer(torch.arange(4),torch.arange(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dfb93a",
   "metadata": {},
   "source": [
    "Source: http://www.cmap.polytechnique.fr/~nikolaus.hansen/evco_11_1_1_0.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "50f03bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newcmaes_step(x, obj, params):\n",
    "    l = params[\"l\"]\n",
    "    mu = params[\"mu\"]\n",
    "    C = params[\"C\"]\n",
    "    pc = params[\"pc\"]\n",
    "    cc = params[\"cc\"]\n",
    "    ccov = params[\"ccov\"]\n",
    "    acov = params[\"acov\"]\n",
    "    s = params[\"s\"]\n",
    "    ps = params[\"ps\"]\n",
    "    cs = params[\"cs\"]\n",
    "    ds = params[\"ds\"]\n",
    "    chi = params[\"chi\"]\n",
    "    n = x.size(0)\n",
    "    \n",
    "    #compute B and D\n",
    "    B, D_squared, B_transpose = torch.linalg.svd(C)\n",
    "    D = torch.diag(torch.sqrt(D_squared))\n",
    "    BD = torch.matmul(B,D)\n",
    "    \n",
    "    #Sample offspring\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(n), torch.eye(n))\n",
    "    z = m.sample((l,))\n",
    "    offspring = x + s * torch.matmul(BD, z) #FIX!!!!!\n",
    "        \n",
    "    #Compute objective on each offspring\n",
    "    evals = torch.zeros(l)\n",
    "    for i in range(l):\n",
    "        evals[i] = obj(offspring[i])\n",
    "        \n",
    "    #Get indices of top mu offspring\n",
    "    top_evals, top_inds = torch.topk(evals, mu, largest=False)\n",
    "    \n",
    "    #Updates\n",
    "    x_new = (1/mu) * torch.sum(offspring[top_inds], dim=0)\n",
    "    z_avg = (1/mu) * torch.sum(z[top_inds])\n",
    "    \n",
    "    #Covariance update\n",
    "    pc_new = (1-cc)*pc + torch.sqrt(cc*(2-cc)*mu) * torch.matmul(BD, z_avg)\n",
    "    \n",
    "    outer_prod_sum = torch.zeros(n,n)\n",
    "    for i in range(mu):\n",
    "        outer_prod_sum += (1/mu) * torch.matmul(z[top_inds[i]], torch.transpose(z[top_inds[i]])) #FIX???\n",
    "    bigZ = torch.matmul(BD, torch.matmul(outer_prod_sum, torch.transpose(BD))) #FIX???\n",
    "    \n",
    "    C_new = ((1-ccov)*C + \n",
    "             ccov * (acov*torch.matmul(pc_new, torch.transpose(pc_new)) +\n",
    "                     (1-acov)*bigZ)) #FIX???\n",
    "    \n",
    "    #Step size update\n",
    "    ps_new = (1-cs)*ps + np.sqrt(cs*(2-cs)*mu) * torch.matmul(B, z_avg)\n",
    "    s_new = s * torch.exp((1/ds) * (torch.norm(ps_new)-chi) / chi)\n",
    "    \n",
    "    return x_new, C_new, pc_new, s_new, ps_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1552e46",
   "metadata": {},
   "source": [
    "Source: https://arxiv.org/pdf/1604.00772.pdf (see pg. 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "21cb7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cmaes_params(n):\n",
    "    l = 4 + np.floor(3 * np.log(n))\n",
    "    mu = np.floor(l/2)\n",
    "    \n",
    "    w_prime = np.log((l+1)/2) - torch.log(torch.arange(l))\n",
    "    \n",
    "    mu_eff = (torch.sum(w_prime[:mu])**2) / torch.sum(w_prime[:mu]**2)\n",
    "    mu_eff_neg = (torch.sum(w_prime[mu:])**2) / torch.sum(w_prime[mu:]**2)\n",
    "    \n",
    "    cm = 1\n",
    "    \n",
    "    cs = (mu_eff + 2) / (n + mu_eff + 5)\n",
    "    ds = 1 + 2 * max(0, np.sqrt((mu_eff-1)/(n+1))-1) + cs\n",
    "    \n",
    "    cc = (4 + mu_eff/n) / (n + 4 + 2*mu_eff/n)\n",
    "    c1 = 2 / ((n+1.3)**2 + mu_eff)\n",
    "    cmu = min(1-c1, 2*(1/4 + mu_eff + 1/mu_eff - 2)/((n+2)**2 + mu_eff))\n",
    "    \n",
    "    amu = 1 + c1/cmu\n",
    "    amu_eff = 1 + (2*mu_eff_neg) / (mu_eff + 2)\n",
    "    a_pd = (1 - c1 - cmu) / (n*cmu)\n",
    "    \n",
    "    sum_w_prime_pos = torch.sum(w[:mu])\n",
    "    sum_w_prime_neg = -torch.sum(w[mu:])\n",
    "    \n",
    "    w = torch.zeros(l)\n",
    "    w[:mu] = w_prime[:mu] / sum_w_prime_pos\n",
    "    w[mu:] = min(amu, amu_eff, a_pd) * w_prime[mu:] / sum_w_prime_neg\n",
    "    \n",
    "    chi = np.sqrt(1 - 1/(4*n) + 1/(21*n**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d95c78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - finish hs and w_circle\n",
    "def cmaes_step(x, obj, params):\n",
    "    #Set parameters\n",
    "    l = params[\"l\"]\n",
    "    mu = params[\"mu\"]\n",
    "    mu_eff = params[\"mu_eff\"]\n",
    "    C = params[\"C\"]\n",
    "    pc = params[\"pc\"]\n",
    "    cc = params[\"cc\"]\n",
    "    cm = params[\"cm\"]\n",
    "    c1 = params[\"c1\"]\n",
    "    cmu = params[\"cmu\"]\n",
    "    s = params[\"s\"]\n",
    "    ps = params[\"ps\"]\n",
    "    cs = params[\"cs\"]\n",
    "    ds = params[\"ds\"]\n",
    "    chi = params[\"chi\"]\n",
    "    w = params[\"w\"]\n",
    "    n = x.size(0)\n",
    "    \n",
    "    \n",
    "    #Calculate B,D\n",
    "    B, D_squared, B_transpose = torch.linalg.svd(C)\n",
    "    D = torch.diag(torch.sqrt(D_squared))\n",
    "    sqrtCinv = torch.matmul(B, torch.matmul(1/D, B_transpose))\n",
    "    \n",
    "    #Sample offspring\n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(n), torch.eye(n))\n",
    "    z = m.sample((l,))\n",
    "    y = torch.matmul(BD, z)\n",
    "    offspring = x + s*y\n",
    "    \n",
    "    #Compute objective on each offspring\n",
    "    evals = torch.zeros(l)\n",
    "    for i in range(l):\n",
    "        evals[i] = obj(offspring[i])\n",
    "    \n",
    "    #Get indices of top mu offspring\n",
    "    top_evals, top_inds = torch.topk(evals, mu, largest=False)\n",
    "    \n",
    "    #Selection and recombination\n",
    "    y_avg = torch.zeros(n)\n",
    "    for i in range(mu):\n",
    "        y_avg += w[i] * y[top_inds[i]]\n",
    "    x_new = x + cm*s*y_avg\n",
    "\n",
    "    #Covariance update    \n",
    "    hs = 1#Annoying\n",
    "    dhs = (1-hs) * cc * (2-cc)\n",
    "    \n",
    "    w_circle = torch.zeros(l)\n",
    "    w_circle[:mu] = w[:mu]\n",
    "    #TRICKY!#w_circle[mu:] = w[mu:] * (n/torch.norm)\n",
    "    \n",
    "    pc = (1-cc)*pc + hs*np.sqrt(cc*(2-cc)*mu_eff)*y_avg\n",
    "\n",
    "    outer_prod_sum = torch.zeros(n,n)\n",
    "    for i in range(l):\n",
    "        outer_prod_sum += w_circle[i] * torch.matmul(y[top_inds[i]], torch.transpose(y[top_inds[i]])) #FIX???\n",
    "    \n",
    "    C = ((1 + c1*dhs - c1 - cmu*sumw)*C +\n",
    "         c1*torch.matmul(pc, torch.transpose(pc)) +\n",
    "         cmu*outer_prod_sum) #FIX???\n",
    "    \n",
    "    #Step size update\n",
    "    ps_new = (1-cs)*ps + np.sqrt(cs*(2-cs)*mu_eff) * torch.matmul(sqrtCinv, y_avg) #TODO C^-1/2!!!\n",
    "    s_new = s * torch.exp((cs/ds) * (torch.norm(ps)/chi - 1))\n",
    "    \n",
    "    return x_new, C_new, pc_new, s_new, ps_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13f77ce",
   "metadata": {},
   "source": [
    "## Optimizer Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6f16f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(optimizer, x, obj):\n",
    "    if optimizer == \"gd\":\n",
    "        x_new = gd_step(x, obj, parameters[\"gd\"])\n",
    "        \n",
    "    elif optimizer == \"momentum\":\n",
    "        x_new, v_new = momentum_step(x, obj, parameters[\"momentum\"])\n",
    "        parameters[\"momentum\"][\"v\"] = v_new\n",
    "        \n",
    "    elif optimizer == \"adagrad\":\n",
    "        x_new, s_new = adagrad_step(x, obj, parameters[\"adagrad\"])\n",
    "        parameters[\"adagrad\"][\"s\"] = s_new\n",
    "        \n",
    "    elif optimizer == \"rmsprop\":\n",
    "        pass\n",
    "    \n",
    "    elif optimizer == \"adam\":\n",
    "        x_new, v_new, s_new = adam_step(x, obj, parameters[\"adam\"])\n",
    "        parameters[\"adam\"][\"v\"] = v_new\n",
    "        parameters[\"adam\"][\"s\"] = s_new\n",
    "    \n",
    "    elif optimizer == \"oldcmaes\":\n",
    "        x_new, C_new, pc_new, s_new, ps_new = oldcmaes_step(x, obj, parameters[\"oldcmaes\"])\n",
    "        parameters[\"oldcmaes\"][\"C\"] = C_new\n",
    "        parameters[\"oldcmaes\"][\"pc\"] = pc_new\n",
    "        parameters[\"oldcmaes\"][\"s\"] = s_new\n",
    "        parameters[\"oldcmaes\"][\"ps\"] = ps_new\n",
    "        \n",
    "    elif optimizer == \"newcmaes\":\n",
    "        x_new, C_new, pc_new, s_new, ps_new = newcmaes_step(x, obj, parameters[\"oldcmaes\"])\n",
    "        parameters[\"newcmaes\"][\"C\"] = C_new\n",
    "        parameters[\"newcmaes\"][\"pc\"] = pc_new\n",
    "        parameters[\"newcmaes\"][\"s\"] = s_new\n",
    "        parameters[\"newcmaes\"][\"ps\"] = ps_new\n",
    "        \n",
    "    elif optimizer == \"cmaes\":\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        print(\"Optimizer\", optimizer, \"not found.\")\n",
    "        \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11501c54",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "028dac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_params(n):\n",
    "    gd_params = {\n",
    "        \"lr\": 0.001\n",
    "    }\n",
    "\n",
    "    momentum_params = {\n",
    "        \"lr\": 0.001,\n",
    "        \"v\": 0,\n",
    "        \"decay\": 0.9\n",
    "    }\n",
    "\n",
    "    adagrad_params = {\n",
    "        \"lr\": 1,\n",
    "        \"s\": 0\n",
    "    }\n",
    "\n",
    "    rmsprop_params = {}\n",
    "\n",
    "    adam_params = {\n",
    "        \"lr\": 0.1,\n",
    "        \"v\": 0,\n",
    "        \"s\": 0,\n",
    "        \"v_decay\": 0.9,\n",
    "        \"s_decay\": 0.999,\n",
    "        \"k\": 0\n",
    "    }\n",
    "    \n",
    "    l = int(4 + np.floor(3*np.log(n)))\n",
    "    mu = int(np.floor(l/4))\n",
    "    chi = np.sqrt(n) * (1 - 1/(4*n) + 1/(21*n**2))\n",
    "    oldcmaes_params = {\n",
    "        \"l\": l,\n",
    "        \"mu\": mu,\n",
    "        \"C\": torch.eye(n),\n",
    "        \"pc\": 0,\n",
    "        \"cc\": 4 / (n+4),\n",
    "        \"ccov\": 2 / (n + np.sqrt(2))**2,\n",
    "        \"s\": 1,\n",
    "        \"ps\": 0,\n",
    "        \"cs\": 4/(n+4),\n",
    "        \"ds\": 1 + (n+4)/4,\n",
    "        \"chi\": chi\n",
    "    }\n",
    "    \n",
    "    acov = 1/mu\n",
    "    newcmaes_params = {\n",
    "        \"l\": l,\n",
    "        \"mu\": mu,\n",
    "        \"C\": torch.eye(n),\n",
    "        \"pc\": 0,\n",
    "        \"cc\": 4 / (n+4),\n",
    "        \"ccov\": acov*2/(n+np.sqrt(2))**2 + (1-acov)*min(1, (2*mu-1)/((n+2)**2 + mu)),\n",
    "        \"acov\": acov,\n",
    "        \"s\": 1,\n",
    "        \"ps\": 0,\n",
    "        \"cs\": 4/(n+4),\n",
    "        \"ds\": 1 + (n+4)/4,\n",
    "        \"chi\": chi\n",
    "    }\n",
    "    \n",
    "    #TODO\n",
    "    cmaes_params = {}\n",
    "\n",
    "    parameters = {\n",
    "        \"gd\": gd_params,\n",
    "        \"momentum\": momentum_params,\n",
    "        \"adagrad\": adagrad_params,\n",
    "        \"rmsprop\": rmsprop_params,\n",
    "        \"adam\": adam_params,\n",
    "        \"oldcmaes\": oldcmaes_params,\n",
    "        \"newcmaes\": newcmaes_params,\n",
    "        \"cmaes\": cmaes_params\n",
    "    }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a820b",
   "metadata": {},
   "source": [
    "## Training/Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "55f0eaf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial x: tensor([-0.4202,  0.7429, -1.8678,  1.6296, -0.3195, -1.4256,  1.1357, -0.2281,\n",
      "        -0.5613, -1.1561], requires_grad=True)\n",
      "epoch 0 | 2668.9189453125\n",
      "epoch 50 | 10.202725410461426\n",
      "epoch 100 | 8.658751487731934\n",
      "epoch 150 | 8.111798286437988\n",
      "epoch 200 | 7.730213165283203\n",
      "epoch 250 | 7.432351589202881\n",
      "epoch 300 | 7.1824631690979\n",
      "epoch 350 | 6.960973262786865\n",
      "epoch 400 | 6.75704288482666\n",
      "epoch 450 | 6.564112186431885\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "optimizer = \"adam\"\n",
    "obj = rosenbrock\n",
    "x = torch.normal(0,1,(10,), requires_grad=True)\n",
    "print(\"Initial x:\", x)\n",
    "\n",
    "parameters = set_params(10)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"epoch\", epoch, \"|\",obj(x).item())\n",
    "        #print(x)\n",
    "    x = step(optimizer, x, obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70fd0ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([0.0,0.0,0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a160b0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rosenbrock(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e946d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "tensor(2., grad_fn=<AddBackward0>)\n",
      "tensor([-12., -12.,   0.])\n",
      "tensor([0.0120, 0.0120, 0.0000], grad_fn=<SubBackward0>)\n",
      "tensor(1.9663, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(t)\n",
    "L = rosenbrock(t)\n",
    "print(L)\n",
    "L.backward()\n",
    "print(t.grad)\n",
    "newt = t - .001*t.grad\n",
    "print(newt)\n",
    "print(rosenbrock(newt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d539da91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1176,  1.0937,  1.1792],\n",
      "        [-1.1386,  0.6213, -0.8826],\n",
      "        [ 1.1929, -0.9009,  0.3181],\n",
      "        [-1.4222,  0.3023, -1.2437],\n",
      "        [ 0.4007, -1.0267,  1.2267]])\n",
      "tensor([2.6007, 2.4616, 2.3357, 3.6608, 2.7196])\n",
      "tensor([3.6608, 2.7196])\n",
      "tensor([[-1.4222,  0.3023, -1.2437],\n",
      "        [ 0.4007, -1.0267,  1.2267]])\n"
     ]
    }
   ],
   "source": [
    "m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(3), torch.eye(3))\n",
    "#offspring = m.sample()\n",
    "offspring = m.sample((5,))\n",
    "\n",
    "print(offspring)\n",
    "\n",
    "evals = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    evals[i] = sphere(offspring[i])\n",
    "\n",
    "print(evals)\n",
    "\n",
    "top_vals, top_inds = torch.topk(evals, 2)\n",
    "\n",
    "print(top_vals)\n",
    "print(offspring[top_inds])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
